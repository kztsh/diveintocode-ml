{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term2 Sprint23 授業課題 \n",
    "## コーディング課題：深層学習RNNスクラッチ(リカレントニューラルネットワーク)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SimpleRNNのフォワードプロパゲーション実装\n",
    "SimpleRNNのクラスSimpleRNNを作成する。基本構造はFCクラスと同じになる。\n",
    "\n",
    "今回はバッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記する。  \n",
    "活性化関数はtanhとして進めるが、これまでのニューラルネットワーク同様にReLUなどに置き換えられる。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになる。ndarrayのshapeがどうなるかを併記している。\n",
    "\n",
    "$$a_t = x_{t}\\cdot W_{x} + h_{t-1}\\cdot W_{h} + b$$\n",
    "$$h_t = tanh(a_t)$$\n",
    "\n",
    "$a_t$ : 時刻$t$の活性化関数を通す前の状態 (batch_size, n_nodes)  \n",
    "$h_t$ : 時刻$t$の状態・出力 (batch_size, n_nodes)  \n",
    "$x_t$ : 時刻$t$の入力 (batch_size, n_features)  \n",
    "$W_x$ : 入力に対する重み (n_features, n_nodes)  \n",
    "$h_{t−1}$ : 時刻${t-1}$の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)  \n",
    "$W_h$ : 状態に対する重み。 (n_nodes, n_nodes)  \n",
    "$b$ : バイアス項 (1,)  \n",
    "\n",
    "初期状態$h_0$は全て$0$とすることが多いが、任意の値を与えることも可能。\n",
    "\n",
    "上記の処理を系列数n_sequences回繰り返すことになる。  \n",
    "RNN全体への入力$x$は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していく。\n",
    "\n",
    "分類問題であれば、それぞれの時刻の$h$に対して全結合層とソフトマックス関数（またはシグモイド関数）を使用する。  \n",
    "出力は最後の$h$だけを使用する場合と、全ての$h$を使う場合がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 小さな配列でのフォワードプロパゲーションの実験\n",
    "小さな配列でフォワードプロパゲーションを考えてみる。\n",
    "\n",
    "入力$x$、初期状態$h$、重み$w_x$と$w_h$、バイアスbを次のようにする。\n",
    "\n",
    "ここで配列$x$の軸はバッチサイズ、系列数、特徴量数の順番。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "batch_size = x.shape[0] # 1\n",
    "n_sequences = x.shape[1] # 3\n",
    "n_features = x.shape[2] # 2\n",
    "n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((batch_size, n_nodes))\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  1\n",
      "n_sequences:  3\n",
      "n_features:  2\n",
      "n_nodes:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"batch_size: \", batch_size)\n",
    "print(\"n_sequences: \", n_sequences)\n",
    "print(\"n_features: \", n_features)\n",
    "print(\"n_nodes: \", n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションの出力が次のようになることを作成したコードで確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際に確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchRNN:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        self.w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
    "        self.w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
    "        self.batch_size = 1\n",
    "        self.h = np.zeros((1, 4))\n",
    "        self.b = np.array([1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        a_t = np.dot(x, self.w_x) + np.dot(self.h, self.w_h) + self.b\n",
    "        self.h = np.tanh(a_t)\n",
    "        return self.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79494228 0.81839002 0.83939649 0.85584174]]\n"
     ]
    }
   ],
   "source": [
    "rnn = ScratchRNN()\n",
    "\n",
    "for i in range(n_sequences):\n",
    "    h_test = rnn.forward(x[:,i,:])\n",
    "print(h_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
