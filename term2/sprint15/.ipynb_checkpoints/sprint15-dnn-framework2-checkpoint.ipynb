{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term1 Sprint15 授業課題 \n",
    "## コーディング課題：ディープラーニングフレームワーク2 (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはロジスティック回帰を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ANDゲートの学習データを用意\n",
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**複数の記述方法**  \n",
    "Kerasでは簡素にニューラルネットワークが記述できるが、その書き方にはSequentialモデルとFunctional APIの2種類がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequentialモデル\n",
    "Sequentialクラスを使用した記述方法。\n",
    "\n",
    "[tf.keras.models.Sequential  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential \"tf.keras.models.Sequential  |  TensorFlow\")\n",
    "\n",
    "層のインスタンスをSequentialクラスのコンストラクタにリストで渡すことでモデルを定義する。  \n",
    "層のクラスについては以下のページにまとまっている。\n",
    "\n",
    "[Module: tf.keras.layers  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers \"Module: tf.keras.layers  |  TensorFlow\")\n",
    "\n",
    "ロジスティック回帰を作るために、全結合層のクラス、tf.keras.layers.Denseを使う。  \n",
    "引数に出力のユニット数、活性化関数、入力のユニット数を入れる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/arimoto/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denseクラスは引数で重みの初期化方法、バイアスの有無などの指定も可能。\n",
    "\n",
    "[tf.keras.layers.Dense  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense \"tf.keras.layers.Dense  |  TensorFlow\")\n",
    "\n",
    "作成したモデルの構造はsummaryメソッドで確認することができる。  \n",
    "層ごとの出力のshapeとパラメータ数が併記される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "構造が記述できたら、モデルをコンパイルする。  \n",
    "コンパイル時に損失関数と最適化手法、評価関数を指定する。  \n",
    "損失関数は名前をstringで指定する。  \n",
    "ここでは2値分類のため、binary_crossentropyとなる。  \n",
    "多値分類の場合はcategorical_crossentropy、回帰の場合はmean_squared_errorのようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして学習を行う。scikit-learn同様にfitメソッドを使う設計になっている。  \n",
    "verboseは学習過程の可視化方法のパラメータで、デフォルトの1ではバッチごとに更新されるプログレスバーが表示される。  \n",
    "verboseが0の場合は表示を行わず、2の場合はエポック毎の表示になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1116 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1113 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1110 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1109 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1106 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1103 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1098 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1097 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1088 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1084 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1083 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1082 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1076 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1069 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1067 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1066 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1065 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1059 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1058 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1056 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1054 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1051 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1033 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1027 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1024 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1023 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1017 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1012 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1008 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0997 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0984 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0982 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0981 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0979 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0977 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0976 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0974 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今は用意していないが、検証用データがある場合は、引数validation_dataに与えることで、エポック毎の検証も可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1, \n",
    "                    validation_data=(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定もscikit-learn同様にpredictメソッドを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba:  [0.00248107 0.10684937 0.10662693 0.85164577]\n",
      "y_pred:  [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(x_train)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba: \", y_pred_proba)\n",
    "print(\"y_pred: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果がいらず、評価のみ行う場合はevaluateメソッドも便利。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.09720493853092194\n",
      "Train accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss: ', score[0])\n",
    "print('Train accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequentialモデルのもうひとつの書き方**  \n",
    "Sequentialモデルでは、コンストラクタで層のクラスを渡さず、addメソッドを使って記述する方法もよく使われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**複数層の場合**  \n",
    "ロジスティック回帰ではなく、2層のニューラルネットワークの場合は以下のように記述できる。  \n",
    "2層目以降はinput_shapeを与える必要がない(tf.kerasが自動的に計算するため)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)),\n",
    "            tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "addメソッドを使えば次のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functional APIを使えばより自由度の高いモデル構築が行える。  \n",
    "Sequentialクラスの代わりにModelクラスを使用する。\n",
    "\n",
    "[tf.keras.models.Model  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model \"tf.keras.models.Model  |  TensorFlow\")\n",
    "\n",
    "入力から出力までの流れを記述していき、最後にModelクラスに入力層と出力層のインスタンスを渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,)) # 入力層\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(input_data) # 出力層\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル構造の記述以降はSequentialモデルと全く同じ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**複数層の場合**  \n",
    "4層のニューラルネットワークは以下のように記述できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,))\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この記述方法では枝分かれを表現することもできる。以下は3層目で2つに枝分かれし、次の層で結合している例。\n",
    "\n",
    "[tf.keras.layers.concatenate  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate \"tf.keras.layers.concatenate  |  TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,))\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "y1 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "y2 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "z = tf.keras.layers.concatenate([y1, y2])\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(z)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラッパーとしてのKeras\n",
    "ラッパーとしてのKerasもデフォルトでTensorFlowをバックエンドとして使用しているため、基本的な使い方は同じ。\n",
    "\n",
    "ドキュメントが日本語でも公開されているため、tf.kerasの学習にもそれを使うことが可能。例えば2つの記述方法については以下のページ。\n",
    "\n",
    "[Sequentialモデルのガイド - Keras Documentation](https://keras.io/ja/getting-started/sequential-model-guide/ \"Sequentialモデルのガイド - Keras Documentation\")\n",
    "\n",
    "[Functional APIのガイド - Keras Documentation](https://keras.io/ja/getting-started/functional-api-guide/ \"Functional APIのガイド - Keras Documentation\")\n",
    "\n",
    "compileメソッドで指定できる損失関数もまとまっている。\n",
    "\n",
    "[損失関数 - Keras Documentation](https://keras.io/ja/losses/ \"損失関数 - Keras Documentation\")\n",
    "\n",
    "Sequentialモデルは以下のように書ける。ロジスティック回帰の例。\n",
    "\n",
    "以下のコードのほとんどは上で紹介したtf.kerasと実質的に同じだが、例えば活性化関数を全結合層とは別のクラスとして渡している。  \n",
    "また、最適化手法の部分はtf.train.AdamOptimizerからkeras.optimizers.Adamに変わっている。  \n",
    "tf.kerasではTensorFlow自体の最適化手法クラスを呼んでいるのに対し、KerasではKeras独自の最適化手法クラスを使用するため。  \n",
    "ラッパーとしてのKerasのコードも見る機会が多いので、若干の違いに慣れておくと良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 公式Exampleを分担して実行\n",
    "TensorFLowの公式Exampleを分担して実行する。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表する。\n",
    "\n",
    "**research**\n",
    "\n",
    "定番のモデルから最新のモデルまで多様なコードが公開されている。\n",
    "\n",
    "[models/research at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/research \"models/research at master · tensorflow/models\")\n",
    "\n",
    "**tutorials**\n",
    "\n",
    "TensorFLowのチュートリアルとして用意された簡単なモデルが含まれている。\n",
    "\n",
    "[models/tutorials at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/tutorials \"models/tutorials at master · tensorflow/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Iris（2値分類）をKerasで学習\n",
    "\n",
    "Sprint14で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していく。\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n",
    "\n",
    "**Kerasへの書き換え**\n",
    "\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用する。\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類があるが、これは指定しない。\n",
    "\n",
    "まずは、Sprint14で作成したIrisデータセットに対する2値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!cd gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train loss:  0.06096649542450905\n",
      "Train accuracy:  0.984375\n",
      "Test loss:  0.1363629698753357\n",
      "Test accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Iris（多値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する3値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "# yをonehot表現にする\n",
    "y = to_categorical(y).astype(np.int)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train loss:  0.08936094244321187\n",
      "Train accuracy:  0.9583333\n",
      "Test loss:  0.06781800836324692\n",
      "Test accuracy:  0.96666664\n"
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. House PricesをKerasで学習\n",
    "Sprint14で作成したHouse Pricesデータセットに対する回帰をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\", \"OverallQual\", \"GarageArea\"]]\n",
    "y = df[\"SalePrice\"]\n",
    "X = np.array(X).astype(np.float64)\n",
    "y = np.array(y).astype(np.float64)\n",
    "\n",
    "# 目的変数を対数変換\n",
    "y = np.log(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 標準化\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d89502e2cc00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m history = model.fit(X_train, y_train, batch_size=1, epochs=3, verbose=2, \n\u001b[0;32m---> 15\u001b[0;31m                     validation_data=(X_val, y_val))\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 評価\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m   \u001b[0;34m\"\"\"Utility to initialize uninitialized variables on the fly.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_get_variables\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GRAPH_VARIABLES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeakSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_TF_OPTIMIZERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m     \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python37/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_commit_removals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ior__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=None)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss(MSE): ', train_loss)\n",
    "print('Train MAE: ', train_mae)\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss(MSE): ', test_loss)\n",
    "print('Test MAE: ', test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MNISTをKerasで学習\n",
    "Sprint14で作成したMNISTデータセットによる画像の多値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# データ生成\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# (n_samples, n_channels, height, width)のNCHWに次元整形\n",
    "# 今回はモノクロなのでチャンネル数は1(サンプル数, 高さ, 幅, チャンネル数)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 訓練データから更に検証データを生成\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_val.shape: \", X_val.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_val.shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot = tf.one_hot(\n",
    "                indices=self.y, depth=10, dtype=tf.float32, name='tf_y_onehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# モデルを構築\n",
    "input_data = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, kernel_size=(5, 5, 1), activation='relu', padding=\"valid\", input_shape=(28, 28, 1))(input_data)\n",
    "x = MaxPooling2D(pool_size=(2, 2, 1), padding=\"same\")(x)\n",
    "x = Conv2D(64, kernel_size=(5, 5, 1), activation='relu', padding=\"valid\", input_shape=(28, 28, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2, 1), padding=\"same\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(10, activation='softmax')\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
