{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Enfmmlmav0nY"
   },
   "source": [
    "# Term1 Sprint15 授業課題 \n",
    "## コーディング課題：ディープラーニングフレームワーク2 (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7OJOPCvPwB65",
    "outputId": "26ead38a-f1c9-442a-eb0f-83eaac869c89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!cd gdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JwkoMwhv0na"
   },
   "source": [
    "まずはロジスティック回帰を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4se7l-9v0nb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ANDゲートの学習データを用意\n",
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGo8bUoPv0nf"
   },
   "source": [
    "**複数の記述方法**  \n",
    "Kerasでは簡素にニューラルネットワークが記述できるが、その書き方にはSequentialモデルとFunctional APIの2種類がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfkVfGQav0ng"
   },
   "source": [
    "## Sequentialモデル\n",
    "Sequentialクラスを使用した記述方法。\n",
    "\n",
    "[tf.keras.models.Sequential  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential \"tf.keras.models.Sequential  |  TensorFlow\")\n",
    "\n",
    "層のインスタンスをSequentialクラスのコンストラクタにリストで渡すことでモデルを定義する。  \n",
    "層のクラスについては以下のページにまとまっている。\n",
    "\n",
    "[Module: tf.keras.layers  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers \"Module: tf.keras.layers  |  TensorFlow\")\n",
    "\n",
    "ロジスティック回帰を作るために、全結合層のクラス、tf.keras.layers.Denseを使う。  \n",
    "引数に出力のユニット数、活性化関数、入力のユニット数を入れる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLJZ7Zokv0nh",
    "outputId": "92e4a69f-c495-4d04-c54d-c9f604c489ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/arimoto/anaconda3/envs/python37/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQg8cJWXv0nn"
   },
   "source": [
    "Denseクラスは引数で重みの初期化方法、バイアスの有無などの指定も可能。\n",
    "\n",
    "[tf.keras.layers.Dense  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense \"tf.keras.layers.Dense  |  TensorFlow\")\n",
    "\n",
    "作成したモデルの構造はsummaryメソッドで確認することができる。  \n",
    "層ごとの出力のshapeとパラメータ数が併記される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfOitmbOv0nn",
    "outputId": "9a6278c0-2c9c-40c5-ee56-c6690a72a15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5AhbPNfKv0nr"
   },
   "source": [
    "構造が記述できたら、モデルをコンパイルする。  \n",
    "コンパイル時に損失関数と最適化手法、評価関数を指定する。  \n",
    "損失関数は名前をstringで指定する。  \n",
    "ここでは2値分類のため、binary_crossentropyとなる。  \n",
    "多値分類の場合はcategorical_crossentropy、回帰の場合はmean_squared_errorのようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0z8opR8v0ns"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rq9_ZbyRv0nv"
   },
   "source": [
    "そして学習を行う。scikit-learn同様にfitメソッドを使う設計になっている。  \n",
    "verboseは学習過程の可視化方法のパラメータで、デフォルトの1ではバッチごとに更新されるプログレスバーが表示される。  \n",
    "verboseが0の場合は表示を行わず、2の場合はエポック毎の表示になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5I1xTPFv0nw",
    "outputId": "9301ef84-096b-4d7f-b36f-bd7f69a7052a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1117 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1116 - acc: 1.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1115 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1113 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1110 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1109 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1106 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1105 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1103 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1100 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1098 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1097 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1095 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1094 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1091 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1089 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1088 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1084 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1083 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1082 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1076 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1071 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1069 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1067 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1066 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1065 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1060 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1059 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1058 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1056 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1055 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1054 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1052 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1051 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1049 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1046 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1041 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1039 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1036 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1033 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1031 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1027 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1024 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1023 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1020 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1018 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1017 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1014 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1013 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1012 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1011 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1008 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.1007 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1005 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1004 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1003 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0997 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0994 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0993 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0991 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0989 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0985 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0984 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0982 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0981 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.0980 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.0979 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0977 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0976 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0974 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOHOL9FNv0n3"
   },
   "source": [
    "今は用意していないが、検証用データがある場合は、引数validation_dataに与えることで、エポック毎の検証も可能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLUxmVZ1v0n4"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1, \n",
    "                    validation_data=(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kbJkng6ev0n7"
   },
   "source": [
    "推定もscikit-learn同様にpredictメソッドを使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97zT21uDv0n8",
    "outputId": "f78da564-f0cc-47a2-8fd7-5ee2ba38f230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba:  [0.00248107 0.10684937 0.10662693 0.85164577]\n",
      "y_pred:  [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(x_train)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba: \", y_pred_proba)\n",
    "print(\"y_pred: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DTKEkEBKv0oA"
   },
   "source": [
    "結果がいらず、評価のみ行う場合はevaluateメソッドも便利。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4a7A6-mdv0oB",
    "outputId": "40726ed3-82aa-4371-a2a9-3db9b04bd2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.09720493853092194\n",
      "Train accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss: ', score[0])\n",
    "print('Train accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DsLDNma_v0oF"
   },
   "source": [
    "**Sequentialモデルのもうひとつの書き方**  \n",
    "Sequentialモデルでは、コンストラクタで層のクラスを渡さず、addメソッドを使って記述する方法もよく使われる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsnzFNO3v0oG"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid, input_shape=(2,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZPeN20Dv0oK"
   },
   "source": [
    "**複数層の場合**  \n",
    "ロジスティック回帰ではなく、2層のニューラルネットワークの場合は以下のように記述できる。  \n",
    "2層目以降はinput_shapeを与える必要がない(tf.kerasが自動的に計算するため)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyeUTlHEv0oL"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)),\n",
    "            tf.keras.layers.Dense(1, activation = tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N61XG5GKv0oQ"
   },
   "source": [
    "addメソッドを使えば次のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sboa2ZR5v0oR"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.relu, input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQTLiT1yv0oU"
   },
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tYcOnjudv0oV"
   },
   "source": [
    "Functional APIを使えばより自由度の高いモデル構築が行える。  \n",
    "Sequentialクラスの代わりにModelクラスを使用する。\n",
    "\n",
    "[tf.keras.models.Model  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model \"tf.keras.models.Model  |  TensorFlow\")\n",
    "\n",
    "入力から出力までの流れを記述していき、最後にModelクラスに入力層と出力層のインスタンスを渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dA4oXlWIv0oW"
   },
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,)) # 入力層\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(input_data) # 出力層\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96b0AH19v0oZ"
   },
   "source": [
    "モデル構造の記述以降はSequentialモデルと全く同じ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veZUXBR4v0ob"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk1-talwv0of"
   },
   "source": [
    "**複数層の場合**  \n",
    "4層のニューラルネットワークは以下のように記述できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UO6jiMwtv0oh"
   },
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,))\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m8zzEg7Jv0ol"
   },
   "source": [
    "この記述方法では枝分かれを表現することもできる。以下は3層目で2つに枝分かれし、次の層で結合している例。\n",
    "\n",
    "[tf.keras.layers.concatenate  |  TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate \"tf.keras.layers.concatenate  |  TensorFlow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcORSsUlv0oo"
   },
   "outputs": [],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(2,))\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "y1 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "y2 = tf.keras.layers.Dense(10, activation=tf.nn.relu)(x)\n",
    "z = tf.keras.layers.concatenate([y1, y2])\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(z)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_EtCpDLMv0or"
   },
   "source": [
    "## ラッパーとしてのKeras\n",
    "ラッパーとしてのKerasもデフォルトでTensorFlowをバックエンドとして使用しているため、基本的な使い方は同じ。\n",
    "\n",
    "ドキュメントが日本語でも公開されているため、tf.kerasの学習にもそれを使うことが可能。例えば2つの記述方法については以下のページ。\n",
    "\n",
    "[Sequentialモデルのガイド - Keras Documentation](https://keras.io/ja/getting-started/sequential-model-guide/ \"Sequentialモデルのガイド - Keras Documentation\")\n",
    "\n",
    "[Functional APIのガイド - Keras Documentation](https://keras.io/ja/getting-started/functional-api-guide/ \"Functional APIのガイド - Keras Documentation\")\n",
    "\n",
    "compileメソッドで指定できる損失関数もまとまっている。\n",
    "\n",
    "[損失関数 - Keras Documentation](https://keras.io/ja/losses/ \"損失関数 - Keras Documentation\")\n",
    "\n",
    "Sequentialモデルは以下のように書ける。ロジスティック回帰の例。\n",
    "\n",
    "以下のコードのほとんどは上で紹介したtf.kerasと実質的に同じだが、例えば活性化関数を全結合層とは別のクラスとして渡している。  \n",
    "また、最適化手法の部分はtf.train.AdamOptimizerからkeras.optimizers.Adamに変わっている。  \n",
    "tf.kerasではTensorFlow自体の最適化手法クラスを呼んでいるのに対し、KerasではKeras独自の最適化手法クラスを使用するため。  \n",
    "ラッパーとしてのKerasのコードも見る機会が多いので、若干の違いに慣れておくと良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mX6vq0uiv0os"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.01), metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCR2fiuuv0ou"
   },
   "source": [
    "## 1. 公式Exampleを分担して実行\n",
    "TensorFLowの公式Exampleを分担して実行する。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表する。\n",
    "\n",
    "**research**\n",
    "\n",
    "定番のモデルから最新のモデルまで多様なコードが公開されている。\n",
    "\n",
    "[models/research at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/research \"models/research at master · tensorflow/models\")\n",
    "\n",
    "**tutorials**\n",
    "\n",
    "TensorFLowのチュートリアルとして用意された簡単なモデルが含まれている。\n",
    "\n",
    "[models/tutorials at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/tutorials \"models/tutorials at master · tensorflow/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Sjy_i_Mv0ov"
   },
   "source": [
    "## 2. Iris（2値分類）をKerasで学習\n",
    "\n",
    "Sprint14で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していく。\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n",
    "\n",
    "**Kerasへの書き換え**\n",
    "\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用する。\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類があるが、これは指定しない。\n",
    "\n",
    "まずは、Sprint14で作成したIrisデータセットに対する2値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XO8qfkyv0o0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70XDxCQ-v0o3",
    "outputId": "81119a01-34df-4bfb-c8ef-c2b77f19b75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train loss:  0.06096649542450905\n",
      "Train accuracy:  0.984375\n",
      "Test loss:  0.1363629698753357\n",
      "Test accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75wajWkvv0o6"
   },
   "source": [
    "## 3. Iris（多値分類）をKerasで学習\n",
    "Sprint14で作成したIrisデータセットに対する3値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPq78zbuv0o7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "# yをonehot表現にする\n",
    "y = to_categorical(y).astype(np.int)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiEQU7icv0o9",
    "outputId": "096123a8-6169-4d3c-d75a-3f2289d7cc25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train loss:  0.08936094244321187\n",
      "Train accuracy:  0.9583333\n",
      "Test loss:  0.06781800836324692\n",
      "Test accuracy:  0.96666664\n"
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsIjlOuKv0pB"
   },
   "source": [
    "## 4. House PricesをKerasで学習\n",
    "Sprint14で作成したHouse Pricesデータセットに対する回帰をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EleJE6HEv0pB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\", \"OverallQual\", \"GarageArea\"]]\n",
    "y = df[\"SalePrice\"]\n",
    "X = np.array(X).astype(np.float64)\n",
    "y = np.array(y).astype(np.float64)\n",
    "\n",
    "# 目的変数を対数変換\n",
    "y = np.log(y)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 標準化\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "_7d631o2v0pF",
    "outputId": "5134435b-feb1-4329-a249-8d66f082c15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train loss(MSE):  0.04912025333089032\n",
      "Train MAE:  0.16658528\n",
      "Test loss(MSE):  0.06125243304118718\n",
      "Test MAE:  0.1624182\n"
     ]
    }
   ],
   "source": [
    "# モデルを構築\n",
    "input_data = tf.keras.layers.Input(shape=(4,))\n",
    "x = tf.keras.layers.Dense(50, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(100, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(1, activation=None)(x)\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=10, epochs=100, verbose=0, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss(MSE): ', train_loss)\n",
    "print('Train MAE: ', train_mae)\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss(MSE): ', test_loss)\n",
    "print('Test MAE: ', test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L9ICcIZv0pJ"
   },
   "source": [
    "## 5. MNISTをKerasで学習\n",
    "Sprint14で作成したMNISTデータセットによる画像の多値分類をKerasに書き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pWawv0Ngv0pK",
    "outputId": "ca52d345-66a3-4cd7-d6b9-eba38b1c6228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (48000, 28, 28, 1)\n",
      "X_val.shape:  (12000, 28, 28, 1)\n",
      "y_train.shape:  (48000, 10)\n",
      "y_val.shape:  (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# データ生成\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# (n_samples, n_channels, height, width)のNCHWに次元整形\n",
    "# 今回はモノクロなのでチャンネル数は1(サンプル数, 高さ, 幅, チャンネル数)\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# yをonehot表現にする\n",
    "y_train = to_categorical(y_train).astype(np.int)\n",
    "y_test = to_categorical(y_test).astype(np.int)\n",
    "\n",
    "# 訓練データから更に検証データを生成\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_val.shape: \", X_val.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"y_val.shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1173
    },
    "colab_type": "code",
    "id": "Rb0J9Klqv0pO",
    "outputId": "e6ee76b4-8c63-42a4-cce4-648dc202df7a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,111,946\n",
      "Trainable params: 1,111,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.3175 - acc: 0.9045 - val_loss: 0.1264 - val_acc: 0.9604\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1703 - acc: 0.9518 - val_loss: 0.1055 - val_acc: 0.9687\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.1709 - acc: 0.9528 - val_loss: 0.1254 - val_acc: 0.9606\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1717 - acc: 0.9546 - val_loss: 0.1011 - val_acc: 0.9708\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.1634 - acc: 0.9574 - val_loss: 0.1317 - val_acc: 0.9585\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1640 - acc: 0.9571 - val_loss: 0.1187 - val_acc: 0.9675\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1824 - acc: 0.9541 - val_loss: 0.1264 - val_acc: 0.9659\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.1765 - acc: 0.9567 - val_loss: 0.1694 - val_acc: 0.9567\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.1666 - acc: 0.9591 - val_loss: 0.1359 - val_acc: 0.9685\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.1895 - acc: 0.9543 - val_loss: 0.1625 - val_acc: 0.9699\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1811 - acc: 0.9567 - val_loss: 0.1870 - val_acc: 0.9569\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.1790 - acc: 0.9574 - val_loss: 0.1642 - val_acc: 0.9704\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 8s 177us/sample - loss: 0.1868 - acc: 0.9563 - val_loss: 0.2047 - val_acc: 0.9597\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.1889 - acc: 0.9562 - val_loss: 0.2052 - val_acc: 0.9556\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.1855 - acc: 0.9556 - val_loss: 0.1261 - val_acc: 0.9667\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.1826 - acc: 0.9573 - val_loss: 0.1319 - val_acc: 0.9707\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 8s 173us/sample - loss: 0.1886 - acc: 0.9558 - val_loss: 0.1188 - val_acc: 0.9730\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 8s 174us/sample - loss: 0.1785 - acc: 0.9585 - val_loss: 0.1323 - val_acc: 0.9717\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 8s 175us/sample - loss: 0.1900 - acc: 0.9577 - val_loss: 0.2268 - val_acc: 0.9607\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 8s 176us/sample - loss: 0.2058 - acc: 0.9560 - val_loss: 0.1553 - val_acc: 0.9697\n",
      "Train loss:  0.10596543499733842\n",
      "Train accuracy:  0.9755\n",
      "Test loss:  0.15082654390343445\n",
      "Test accuracy:  0.9686\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# モデルを構築\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding=\"valid\", \n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', padding=\"valid\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=50, epochs=20, verbose=1, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# 評価\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss: ', train_score[0])\n",
    "print('Train accuracy: ', train_score[1])\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: ', test_score[0])\n",
    "print('Test accuracy: ', test_score[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sprint15-dnn-framework2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
