{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term1 Sprint12 授業課題 \n",
    "## コーディング課題：畳み込みニューラルネットワーク(CNN)スクラッチ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していく。\n",
    "\n",
    "Sprint11で作成したディープニューラルネットワークのクラスを拡張する形でCNNを作成する。  \n",
    "まず、Sprint12で1次元畳み込み層を作成し、畳み込みの基礎を理解することを目指す。  \n",
    "そして、Sprint13で一般的に画像に対して使われる2次元畳み込み層とプーリング層を作成する。\n",
    "\n",
    "**1次元畳み込み層**  \n",
    "畳み込みニューラルネットワークは画像に対して使われる2次元畳み込みが代表的だが、理解を容易にするためにまずは1次元畳み込みを実装する。  \n",
    "1次元畳み込みは系列データで使われることが多い。  \n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまでがフレームワークで一般的に用意されている。\n",
    "\n",
    "**データセットの用意**  \n",
    "引き続きMNISTデータセットを使用する。  \n",
    "1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力する。\n",
    "\n",
    "**CNN分類器クラスの作成**  \n",
    "1次元畳み込みニューラルネットワークモデルのクラスScratch1dCNNClassifierを作成する。  \n",
    "Sprint11で作成したScratchDeepNeuralNetrowkClassifierを元にする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成する。  \n",
    "基本構造はsprint11で作成したFCクラスと同じになる。  \n",
    "なお、重みの初期化に関するクラスは必要に応じて作り変える。Xavierの初期値などを使う点は全結合層と同様。\n",
    "\n",
    "ここではパディングは考えず、ストライドも1に固定する。  \n",
    "また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応する。  \n",
    "この部分の拡張はアドバンス課題とする。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになる。\n",
    "$$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$$\n",
    "$a_i$ : 出力される配列のi番目の値  \n",
    "$F$ : フィルタのサイズ  \n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値  \n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "$b$ : バイアス項\n",
    "\n",
    "全てスカラーとなる。\n",
    "\n",
    "次に更新式は以下のようになる。ここがAdaGradなどに置き換えられる点は全結合層と同様。\n",
    "$$w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s}$$\n",
    "\n",
    "$$b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$に関する損失$L$の勾配\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$に関する損失$L$の勾配\n",
    "\n",
    "勾配$\\frac{\\partial L}{\\partial w_s}$や$\\frac{\\partial L}{\\partial b}$を求めるためのバックプロパゲーションの数式は以下の通り。\n",
    "$$\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列の$i$番目の値\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "前の層に流す誤差の数式は以下の通り。\n",
    "$$\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列の$j$番目の値\n",
    "\n",
    "ただし、$j−s<0$または$j−s>N_{out}−1$のとき$\\frac{\\partial L}{\\partial a_{(j-s)}}=0$となる。\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていること。  \n",
    "この場合は共有されている分の誤差を全て足すことで勾配を求める。  \n",
    "計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化する。どのように変化するかは以下の数式から求められる。  \n",
    "パディングやストライドも含めている。この計算を行う関数を作成する。\n",
    "\n",
    "$$N_{out} =  \\frac{N_{in}+2P-F}{S} + 1$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）  \n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）  \n",
    "$P$ : ある方向へのパディングの数  \n",
    "$F$ : フィルタのサイズ  \n",
    "$S$ : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認する。  \n",
    "入力$x$、重み$w$、バイアス$b$を次のようにする。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションをすると出力は次のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([35, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にバックプロパゲーションを考えます。誤差は次のようであったとする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バックプロパゲーションをすると次のような値になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**実装上の工夫**  \n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構わない。  \n",
    "しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考える。\n",
    "$$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$$\n",
    "\n",
    "バイアス項は単純な足し算のため、重みの部分を見る。  \n",
    "$$\\sum_{s=0}^{F-1}x_{(i+s)}w_s$$\n",
    "\n",
    "これは、xの一部を取り出した配列とwの配列の内積である。  \n",
    "具体的な状況を考えると、以下のようなコードで計算できる。  \n",
    "この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算している。  \n",
    "これは結果的に内積と同様となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "\n",
    "a = np.empty((2, 3))\n",
    "\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法である。  \n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能。\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していく。\n",
    "\n",
    "**参考**\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述である。\n",
    "\n",
    "[Indexing — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html \"Indexing — NumPy v1.15 Manual\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成する。\n",
    "\n",
    "紙やホワイトボードを使い計算グラフを書きながら考える。\n",
    "\n",
    "例えば以下のような$x$, $w$, $b$があった場合は、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力は次のようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力が2チャンネル、出力が3チャンネルの例となる。  \n",
    "計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみる。  \n",
    "計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はない。\n",
    "\n",
    "**補足**\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題がある。  \n",
    "(バッチサイズ、チャンネル数、特徴量数)または(バッチサイズ、特徴量数、チャンネル数)が一般的で、ライブラリによって順番は異なる。（切り替えて使用できるものもある）\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選ぶ。  \n",
    "上記の例ではバッチサイズは考えておらず、(チャンネル数、特徴量数)となっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習・推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えて学習と推定を行う。  \n",
    "出力層だけは全結合層をそのまま使う。\n",
    "\n",
    "チャンネルが複数ある状態では全結合層への入力は行えない。  \n",
    "その段階でのチャンネルは1になるようにするか、平滑化を行う。  \n",
    "平滑化はNumPyのreshapeが使用できる。\n",
    "\n",
    "[numpy.reshape — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html \"numpy.reshape — NumPy v1.15 Manual\")\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことであるため、精度は問わない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. パディングの実装（アドバンス課題）\n",
    "畳み込み層にパディングを加える。  \n",
    "1次元配列の場合、前後にn個特徴量を増やせるようにする。\n",
    "\n",
    "最も単純なパディングは全て0で埋めるゼロパディングであり、CNNでは一般的。  \n",
    "他に端の値を繰り返す方法などもある。\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができる。  \n",
    "この機能も持たせておくと便利。\n",
    "\n",
    "なお、NumPyにはパディングの関数が存在する。\n",
    "\n",
    "[numpy.pad — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.pad.html \"numpy.pad — NumPy v1.15 Manual\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ミニバッチへの対応（アドバンス課題）\n",
    "ここまでの課題はバッチサイズ1で良いとしてきた。  \n",
    "しかし、実際は全結合層同様にミニバッチ学習が行われる。  \n",
    "Conv1dクラスを複数のデータが同時に計算できるように変更する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 任意のストライド数（アドバンス課題）\n",
    "ストライドは1限定の実装をしてきたが、任意のストライド数に対応できるようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
